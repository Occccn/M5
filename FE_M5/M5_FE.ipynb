{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class etc_features(Dataset):\n",
    "    \n",
    "            \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.file_dir = self.__class__.__name__\n",
    "        if not os.path.exists(self.dir + self.file_dir):\n",
    "            os.mkdir(self.dir + self.file_dir)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def save(self ,feature):\n",
    "        with open(self.dir + self.file_dir+'/'+'{0}.joblib'.format(feature.name), mode=\"wb\") as f:\n",
    "            joblib.dump(feature, f, compress=3)\n",
    "\n",
    "        \n",
    "    def create_features(self):\n",
    "        self.data['item_firstday'] = self.data.groupby(['item_id'])['d'].transform('min')\n",
    "        self.data = self.reduce_mem_usage(self.data)\n",
    "        self.save(feature=self.data['item_firstday'])\n",
    "\n",
    "\n",
    "#UMAPで商品波形をクラスタリングする目的で作成、採用せず\n",
    "    def create_umap_features(self):\n",
    "        self.tmp2 = pd.read_pickle('../data/sales_train_validation.pickle')\n",
    "        self.data['store_umap1_cos'] = 0\n",
    "        self.data['store_umap2_cos'] = 0\n",
    "        for store in tmp2['store_id'].unique():\n",
    "            tmp3 = tmp2[tmp2['store_id'] == store].iloc[:,6:]\n",
    "            embedding = umap.UMAP(metric = 'cosine').fit_transform(tmp3)\n",
    "            tmp2.iloc[tmp2[tmp2['store_id'] == store].index , 1919] = embedding[:,0]\n",
    "            tmp2.iloc[tmp2[tmp2['store_id'] == store].index , 1920] = embedding[:,1]\n",
    "        tmp2['id'] = tmp2['id'].apply(lambda x: x.replace('validation' , 'evaluation'))\n",
    "        self.data = self.data.merge(right = tmp2[['id' , 'store_umap1_cos' , 'store_umap2_cos']] , on = 'id' , how = 'left' )\n",
    "        self.data = self.reduce_mem_usage(self.data)\n",
    "        self.save(feature=self.data['store_umap1_cos'])\n",
    "        self.save(feature=self.data['store_umap2_cos'])\n",
    "\n",
    "\n",
    "#売り上げ最大値からのラグ、最小値からのラグ\n",
    "    def create_features(self):\n",
    "        self.data['tmp'] = self.data.groupby(['id']).agg({'demand': ['cummax']})\n",
    "        self.data['tmp_shift1'] = self.data.groupby(['id'])['tmp'].shift(1)\n",
    "        demand_max = np.array(self.data['tmp'])\n",
    "        demand_max_shift1 = np.array(self.data['tmp_shift1'])\n",
    "        import math\n",
    "        cnt_list = []\n",
    "        for i in range(len(demand_max)):\n",
    "            if math.isnan(demand_max_shift1[i]):\n",
    "                cnt_list.append(0)\n",
    "            else:\n",
    "                if demand_max[i] == demand_max_shift1[i]:\n",
    "                    cnt_list.append(0)\n",
    "                else:\n",
    "                    cnt_list.append(1)\n",
    "\n",
    "        self.data['tmp2'] = cnt_list\n",
    "        self.data['demand_max_change'] = self.data.groupby(['id']).agg({'tmp2': ['cumsum']})\n",
    "        self.data['demand_max_lag'] = self.data.groupby(['demand_max_change' , 'id']).cumcount()\n",
    "        self.data['demand_max_lag_shift1'] = self.data.groupby(['id'])['demand_max_lag'].shift(1)\n",
    "        self.data = self.reduce_mem_usage(self.data)\n",
    "        self.save(feature=self.data['demand_max_lag_shift1'])\n",
    "\n",
    "    def create_min_features(self):\n",
    "        self.data['tmp'] = self.data.groupby(['id']).agg({'demand': ['cummin']})\n",
    "        self.data['tmp_shift1'] = self.data.groupby(['id'])['tmp'].shift(1)\n",
    "        demand_max = np.array(self.data['tmp'])\n",
    "        demand_max_shift1 = np.array(self.data['tmp_shift1'])\n",
    "        import math\n",
    "        cnt_list = []\n",
    "        for i in range(len(demand_max)):\n",
    "            if math.isnan(demand_max_shift1[i]):\n",
    "                cnt_list.append(0)\n",
    "            else:\n",
    "                if demand_max[i] == demand_max_shift1[i]:\n",
    "                    cnt_list.append(0)\n",
    "                else:\n",
    "                    cnt_list.append(1)\n",
    "\n",
    "        self.data['tmp2'] = cnt_list\n",
    "        self.data['demand_min_change'] = self.data.groupby(['id']).agg({'tmp2': ['cumsum']})\n",
    "        self.data['demand_min_lag'] = self.data.groupby(['demand_min_change' , 'id']).cumcount()\n",
    "        self.data['demand_min_lag_shift1'] = self.data.groupby(['id'])['demand_min_lag'].shift(1)\n",
    "        self.data = self.reduce_mem_usage(self.data)\n",
    "        self.save(feature=self.data['demand_min_lag_shift1'])\n",
    "              \n",
    "    def shift_features(self):\n",
    "            with open('../features/etc_features' +'/'+ 'demand_min_lag_shift1' + '.joblib', mode=\"rb\") as f:\n",
    "                tmp = joblib.load(f)\n",
    "                self.data = pd.concat([self.data,tmp],axis=1)\n",
    "            for day in range(2,29):\n",
    "                self.data['demand_min_lag_shift{0}'.format(day)] = self.data.groupby(['id'])['demand_min_lag_shift1'].shift(day-1)\n",
    "                self.data = self.reduce_mem_usage(self.data)\n",
    "                self.save(feature=self.data['demand_min_lag_shift{0}'.format(day)])\n",
    "                self.data = self.data.drop(columns = 'demand_min_lag_shift{0}'.format(day))\n",
    "\n",
    "\n",
    "            with open('../features/etc_features' +'/'+ 'demand_max_lag_shift1' + '.joblib', mode=\"rb\") as f:\n",
    "                tmp = joblib.load(f)\n",
    "                self.data = pd.concat([self.data,tmp],axis=1)\n",
    "            for day in range(2,29):\n",
    "                self.data['demand_max_lag_shift{0}'.format(day)] = self.data.groupby(['id'])['demand_max_lag_shift1'].shift(day-1)\n",
    "                self.data = self.reduce_mem_usage(self.data)\n",
    "                self.save(feature=self.data['demand_max_lag_shift{0}'.format(day)])\n",
    "                self.data = self.data.drop(columns = 'demand_max_lag_shift{0}'.format(day) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rolling_lag_Feature(Dataset):\n",
    "    #単純な移動平均\n",
    "\n",
    "        \n",
    "        \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.file_dir = self.__class__.__name__\n",
    "        if not os.path.exists(self.dir + self.file_dir):\n",
    "            os.mkdir(self.dir + self.file_dir)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def save(self ,feature):\n",
    "        with open(self.dir + self.file_dir+'/'+'{0}.joblib'.format(feature.name), mode=\"wb\") as f:\n",
    "            joblib.dump(feature, f, compress=3)\n",
    "\n",
    "    #移動平均\n",
    "    def create_features(self):\n",
    "        for i in range(1,28):\n",
    "            DAYS_PRED = i+1\n",
    "            for size in [7, 28, 56, 84, 168]:\n",
    "                self.data[f\"rolling_lag_mean_t{size}_shift{DAYS_PRED}\"] = self.data.groupby([\"id\"]\n",
    "                                                )[\"demand\"].transform(lambda x: x.shift(DAYS_PRED).rolling(size).mean())\n",
    "                self.data = self.reduce_mem_usage(self.data)\n",
    "                self.save(feature=self.data[f\"rolling_lag_mean_t{size}_shift{DAYS_PRED}\"])\n",
    "      \n",
    "            for size in [7, 28, 56, 84, 168]:\n",
    "                self.data[f\"rolling_lag_sum_t{size}_shift{DAYS_PRED}\"] = self.data.groupby([\"id\"]\n",
    "                                                )[\"demand\"].transform(lambda x: x.shift(DAYS_PRED).rolling(size).sum())\n",
    "                self.data = self.reduce_mem_usage(self.data)\n",
    "                self.save(feature=self.data[f\"rolling_lag_sum_t{size}_shift{DAYS_PRED}\"])\n",
    "              \n",
    "            for size in [7, 28, 56, 84, 168]:\n",
    "                self.data[f\"rolling_lag_std_t{size}_shift{DAYS_PRED}\"] = self.data.groupby([\"id\"]\n",
    "                                                )[\"demand\"].transform(lambda x: x.shift(DAYS_PRED).rolling(size).std())\n",
    "                self.data = self.reduce_mem_usage(self.data)\n",
    "                self.save(feature=self.data[f\"rolling_lag_std_t{size}_shift{DAYS_PRED}\"])\n",
    "                \n",
    "            for size in [7, 28, 56, 84, 168]:\n",
    "                self.data[f\"rolling_lag_max_t{size}_shift{DAYS_PRED}\"] = self.data.groupby([\"id\"]\n",
    "                                                )[\"demand\"].transform(lambda x: x.shift(DAYS_PRED).rolling(size).max())\n",
    "                self.data = self.reduce_mem_usage(self.data)\n",
    "                self.save(feature=self.data[f\"rolling_lag_max_t{size}_shift{DAYS_PRED}\"])\n",
    "\n",
    "            for size in [7, 28, 56, 84, 168]:\n",
    "                self.data[f\"rolling_lag_min_t{size}_shift{DAYS_PRED}\"] = self.data.groupby([\"id\"]\n",
    "                                                )[\"demand\"].transform(lambda x: x.shift(DAYS_PRED).rolling(size).min())\n",
    "                self.data = self.reduce_mem_usage(self.data)\n",
    "                self.save(feature=self.data[f\"rolling_lag_min_t{size}_shift{DAYS_PRED}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class calendar_feature(Dataset):\n",
    "    #\n",
    "        \n",
    "        \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.file_dir = self.__class__.__name__ \n",
    "        if not os.path.exists(self.dir + self.file_dir):\n",
    "            os.mkdir(self.dir + self.file_dir)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def save(self ,feature):\n",
    "        with open(self.dir + self.file_dir+'/'+'{0}.joblib'.format(feature.name), mode=\"wb\") as f:\n",
    "            joblib.dump(feature, f, compress=3)\n",
    "\n",
    "      #カレンダー情報、カーネルをそのまま持ってきた\n",
    "    def create_feature(self):\n",
    "        dt_col = \"date\"\n",
    "        self.data[dt_col] = pd.to_datetime(self.data[dt_col])\n",
    "\n",
    "        attrs = [\n",
    "            \"year\",\n",
    "            \"quarter\",\n",
    "            \"month\",\n",
    "            \"week\",\n",
    "            \"day\",\n",
    "            \"dayofweek\",\n",
    "            \"is_year_end\",\n",
    "            \"is_year_start\",\n",
    "            \"is_quarter_end\",\n",
    "            \"is_quarter_start\",\n",
    "            \"is_month_end\",\n",
    "            \"is_month_start\",]\n",
    "\n",
    "        for attr in attrs:\n",
    "            dtype = np.int16 if attr == \"year\" else np.int8\n",
    "            self.data[attr] = getattr(self.data[dt_col].dt, attr).astype(dtype)\n",
    "            \n",
    "            self.data = self.reduce_mem_usage(self.data)\n",
    "            self.save(feature=self.data[attr])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class price_feature(Dataset):\n",
    "    #\n",
    "        \n",
    "        \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.file_dir = self.__class__.__name__ \n",
    "        if not os.path.exists(self.dir + self.file_dir):\n",
    "            os.mkdir(self.dir + self.file_dir)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def save(self ,feature):\n",
    "        with open(self.dir + self.file_dir+'/'+'{0}.joblib'.format(feature.name), mode=\"wb\") as f:\n",
    "            joblib.dump(feature, f, compress=3)\n",
    "        \n",
    "    #priceに関する基本的な移動平均特徴量\n",
    "    def create_price_feature(self):\n",
    "        \n",
    "        DAYS_PRED = 28\n",
    "        for size in [7, 28, 56, 84, 168]:\n",
    "            self.data[f\"rolling_price_mean_t{size}\"] = self.data.groupby([\"id\"]\n",
    "                                            )[\"sell_price\"].transform(lambda x: x.rolling(size).mean())\n",
    "            self.data = self.reduce_mem_usage(self.data)\n",
    "            self.save(feature=self.data[f\"rolling_price_mean_t{size}\"])\n",
    "            \n",
    "        for size in [7, 28, 56, 84, 168]:\n",
    "            self.data[f\"rolling_price_std_t{size}\"] = self.data.groupby([\"id\"]\n",
    "                                            )[\"sell_price\"].transform(lambda x: x.rolling(size).std())\n",
    "            self.data = self.reduce_mem_usage(self.data)\n",
    "            self.save(feature=self.data[f\"rolling_price_std_t{size}\"])\n",
    "            \n",
    "        for size in [7, 28, 56, 84, 168]:\n",
    "            self.data[f\"rolling_price_max_t{size}\"] = self.data.groupby([\"id\"]\n",
    "                                            )[\"sell_price\"].transform(lambda x: x.rolling(size).max())\n",
    "            self.data = self.reduce_mem_usage(self.data)\n",
    "            self.save(feature=self.data[f\"rolling_price_max_t{size}\"])\n",
    "\n",
    "        for size in [7, 28, 56, 84, 168]:\n",
    "            self.data[f\"rolling_price_min_t{size}\"] = self.data.groupby([\"id\"]\n",
    "                                            )[\"sell_price\"].transform(lambda x: x.rolling(size).min())\n",
    "            self.data = self.reduce_mem_usage(self.data)\n",
    "            self.save(feature=self.data[f\"rolling_price_min_t{size}\"])\n",
    "        \n",
    "        \n",
    "    #pirceの上下のカウント数と変化してからのラグ、かなり効いた効いた    \n",
    "    def create_price_feature3(self):\n",
    "        tmp = self.data.groupby(['id']).agg({'sell_price': ['cumsum', 'cumcount']})\n",
    "        self.data['price_mean'] = (tmp[('sell_price', 'cumsum')] / (tmp[('sell_price', 'cumcount')] + 1))\n",
    "        self.data['price_max'] = self.data.groupby(['id']).agg({'sell_price': ['cummax']})\n",
    "        self.data['price_min'] = self.data.groupby(['id']).agg({'sell_price': ['cummin']})\n",
    "        self.data['price_norm'] = self.data['sell_price'] / self.data['price_mean']\n",
    "        \n",
    "        \n",
    "        self.data = self.reduce_mem_usage(self.data)\n",
    "        self.save(feature=self.data['price_mean'])\n",
    "        self.save(feature=self.data['price_max'])\n",
    "        self.save(feature=self.data['price_min'])\n",
    "        self.save(feature=self.data['price_norm'])\n",
    "\n",
    "        self.data['sell_price_shift1'] = self.data.groupby(['id'])['sell_price'].shift(1)\n",
    "        sell_price = np.array(self.data['sell_price'])\n",
    "        sell_price_shift1 = np.array(self.data['sell_price_shift1'])\n",
    "        import math\n",
    "        cnt_list_up = []\n",
    "        cnt_list_down = []\n",
    "        for i in range(len(sell_price)):\n",
    "            if math.isnan(sell_price_shift1[i]):\n",
    "                cnt_list_up.append(0)\n",
    "                cnt_list_down.append(0)\n",
    "            else:\n",
    "                if sell_price[i] > sell_price_shift1[i]:\n",
    "                    cnt_list_up.append(1)\n",
    "                    cnt_list_down.append(0)\n",
    "                elif sell_price[i] < sell_price_shift1[i]:\n",
    "                    cnt_list_up.append(0)\n",
    "                    cnt_list_down.append(1)\n",
    "                else:\n",
    "                    cnt_list_up.append(0)\n",
    "                    cnt_list_down.append(0)\n",
    "        self.data['up'] = cnt_list_up\n",
    "        self.data['down'] = cnt_list_down\n",
    "        self.data['cnt_price_change_up'] = self.data.groupby(['id']).agg({'up': ['cumsum']})\n",
    "        self.data['cnt_price_change_down'] = self.data.groupby(['id']).agg({'down': ['cumsum']})\n",
    "        self.data['price_change_up_lag'] = self.data.groupby(['cnt_price_change_up' , 'id']).cumcount()\n",
    "        self.data['price_change_down_lag'] = self.data.groupby(['cnt_price_change_down' , 'id']).cumcount()\n",
    "        self.data = self.reduce_mem_usage(self.data)\n",
    "        self.save(feature=self.data['cnt_price_change_up'])\n",
    "        self.save(feature=self.data['price_change_up_lag'])\n",
    "        self.save(feature=self.data['cnt_price_change_down'])\n",
    "        self.save(feature=self.data['price_change_down_lag'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class demand_probability(Dataset):\n",
    "\n",
    "        \n",
    "        \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.file_dir = self.__class__.__name__ \n",
    "        if not os.path.exists(self.dir + self.file_dir):\n",
    "            os.mkdir(self.dir + self.file_dir)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def save(self ,feature):\n",
    "        with open(self.dir + self.file_dir+'/'+'{0}.joblib'.format(feature.name), mode=\"wb\") as f:\n",
    "            joblib.dump(feature, f, compress=3)\n",
    "        \n",
    "\n",
    "##各売り上げ個数の出現確率、売り上げの確率分布の情報をモデルに教えるために作成。効果あり採用した\n",
    "    def create_feature(self):\n",
    "      for size in range(4,11):\n",
    "          def tmp(x):\n",
    "            if x == size:\n",
    "              return 1\n",
    "            else:\n",
    "              return 0\n",
    "\n",
    "          self.data['tmp'] = self.data['demand'].apply(lambda x: tmp(x))  \n",
    "          self.data['tmp2'] = 1     \n",
    "          self.data['length'] = self.data.groupby(['id']).agg({'tmp2': ['cumsum']})\n",
    "          self.data['demand_{0}_prob'.format(size)] = self.data.groupby(['id']).agg({'tmp': ['cumsum']})\n",
    "          self.data['demand_{0}_prob'.format(size)] /= self.data['length']\n",
    "          self.data['demand_{0}_prob_shift1'.format(size)] = self.data.groupby(['id'])['demand_{0}_prob'.format(size)].shift(1)\n",
    "          self.data = self.reduce_mem_usage(self.data)\n",
    "          self.save(feature=self.data['demand_{0}_prob_shift1'.format(size)])\n",
    "\n",
    "\n",
    "    def shift_features(self):\n",
    "        for size in range(11):\n",
    "            with open('../features/demand_probability' +'/'+ 'demand_{0}_prob_shift1'.format(size) + '.joblib', mode=\"rb\") as f:\n",
    "                tmp = joblib.load(f)\n",
    "                self.data = pd.concat([self.data,tmp],axis=1)\n",
    "            for day in range(2,29):\n",
    "                self.data['demand_{0}_prob_shift{1}'.format(size , day)] = self.data.groupby(['id'])['demand_{0}_prob_shift1'.format(size)].shift(day-1)\n",
    "                self.data = self.reduce_mem_usage(self.data)\n",
    "                self.save(feature=self.data['demand_{0}_prob_shift{1}'.format(size , day)])\n",
    "                self.data = self.data.drop(columns = 'demand_{0}_prob_shift{1}'.format(size , day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ordered_TS_mean_encoding(Dataset):\n",
    "    #\n",
    "        \n",
    "        \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.file_dir = self.__class__.__name__ \n",
    "        if not os.path.exists(self.dir + self.file_dir):\n",
    "            os.mkdir(self.dir + self.file_dir)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def save(self ,feature):\n",
    "        with open(self.dir + self.file_dir+'/'+'{0}.joblib'.format(feature.name), mode=\"wb\") as f:\n",
    "            joblib.dump(feature, f, compress=3)\n",
    "        \n",
    "        \n",
    "#targetencoding、リークしないようにTSを採用。効果めちゃくちゃあり、特にprice,idでのencoding効果高かった\n",
    "    def create_Ordered_TS_mean_encoding(self):\n",
    "        self.data['demand'] = self.data['demand'].astype(np.int32)\n",
    "\n",
    "        tmp = self.data.groupby(['id']).agg({'demand': ['cumsum', 'cumcount']})\n",
    "        self.data['Ordered_TS_id'] = (tmp[('demand', 'cumsum')] / (tmp[('demand', 'cumcount')] + 1))\n",
    "        self.data['Ordered_TS_id'] = self.data.groupby(['id'])['Ordered_TS_id'].shift(28)\n",
    "        self.data = self.reduce_mem_usage(self.data)\n",
    "        self.save(feature=self.data['Ordered_TS_id'])\n",
    "        \n",
    "        tmp = self.data.groupby(['id' , 'sell_price']).agg({'demand': ['cumsum', 'cumcount']})\n",
    "        self.data['Ordered_TS_id_price'] = (tmp[('demand', 'cumsum')] / (tmp[('demand', 'cumcount')] + 1))\n",
    "        for i in range(28):\n",
    "            DAYS_PRED = i+1\n",
    "            self.data['Ordered_TS_id_price_shift{0}'.format(DAYS_PRED)] = self.data.groupby(['id' , 'sell_price'])['Ordered_TS_id_price'].shift(DAYS_PRED)\n",
    "            self.data = self.reduce_mem_usage(self.data)\n",
    "            self.save(feature=self.data['Ordered_TS_id_price_shift{0}'.format(DAYS_PRED)])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNAP_Feature(Dataset):\n",
    "    #\n",
    "        \n",
    "        \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.file_dir = self.__class__.__name__ \n",
    "        if not os.path.exists(self.dir + self.file_dir):\n",
    "            os.mkdir(self.dir + self.file_dir)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def save(self ,feature):\n",
    "        with open(self.dir + self.file_dir+'/'+'{0}.joblib'.format(feature.name), mode=\"wb\") as f:\n",
    "            joblib.dump(feature, f, compress=3)\n",
    "        \n",
    "    #SNAPからのラグ、特別な日からのラグはよく効きました。\n",
    "    def create_features_SNAP_LAG(self):\n",
    "        tmp = self.data.groupby(['date'])['snap_CA'].mean()\n",
    "        lag_CA = []\n",
    "        tmp2 = 0\n",
    "        for i in tmp.values:\n",
    "            if i == 0:\n",
    "                tmp2 += 1\n",
    "                lag_CA.append(tmp2)\n",
    "            else:\n",
    "                lag_CA.append(0)\n",
    "                tmp2 = 0\n",
    "                    \n",
    "        tmp = self.data.groupby(['date'])['snap_TX'].mean()\n",
    "        lag_TX = []\n",
    "        tmp2 = 0\n",
    "        for i in tmp.values:\n",
    "            if i == 0:\n",
    "                tmp2 += 1\n",
    "                lag_TX.append(tmp2)\n",
    "            else:\n",
    "                lag_TX.append(0)\n",
    "                tmp2 = 0\n",
    "                \n",
    "        tmp = self.data.groupby(['date'])['snap_WI'].mean()\n",
    "        lag_WI = []\n",
    "        tmp2 = 0\n",
    "        for i in tmp.values:\n",
    "            if i == 0:\n",
    "                tmp2 += 1\n",
    "                lag_WI.append(tmp2)\n",
    "            else:\n",
    "                lag_WI.append(0)\n",
    "                tmp2 = 0\n",
    "        self.data =  self.data['date']\n",
    "        \n",
    "        a= pd.DataFrame({'Lag_SNAP_CA':lag_CA,'Lag_SNAP_TX':lag_TX,'Lag_SNAP_WI':lag_WI,'date':tmp.index})\n",
    "        self.data = pd.merge(self.data,a,how = 'left' ,on='date')\n",
    "        self.data = self.reduce_mem_usage(self.data)\n",
    "        self.save(feature=self.data['Lag_SNAP_CA'])\n",
    "        self.save(feature=self.data['Lag_SNAP_TX'])\n",
    "        self.save(feature=self.data['Lag_SNAP_WI'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
